{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Reasoning NLP (Colab)\n",
    "\n",
    "This notebook runs Reasoning-NLP pipeline (G1->G8) and validates artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def _ensure_ffmpeg():\n",
    "    if Path('/usr/bin/ffmpeg').exists():\n",
    "        print('ffmpeg already installed')\n",
    "        return\n",
    "    subprocess.check_call(['apt-get', 'update', '-y'])\n",
    "    subprocess.check_call(['apt-get', 'install', '-y', 'ffmpeg'])\n",
    "\n",
    "def _ensure_packages():\n",
    "    req = {'jsonschema': 'jsonschema'}\n",
    "    miss = [pip for mod,pip in req.items() if importlib.util.find_spec(mod) is None]\n",
    "    if not miss:\n",
    "        print('python packages already satisfied')\n",
    "        return\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', *miss])\n",
    "\n",
    "_ensure_ffmpeg()\n",
    "_ensure_packages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path('/content/video-summary')\n",
    "BRANCH_NAME = os.environ.get('VIDEO_SUMMARY_BRANCH', '02-member-2-reasoning-nlp')\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.check_call([\n",
    "        'git', 'clone', '--single-branch', '--branch', BRANCH_NAME,\n",
    "        'https://github.com/TCTri205/video-summary.git', str(REPO_DIR)\n",
    "    ])\n",
    "else:\n",
    "    os.chdir(REPO_DIR)\n",
    "    subprocess.check_call(['git', 'fetch', 'origin'])\n",
    "    subprocess.check_call(['git', 'checkout', BRANCH_NAME])\n",
    "    subprocess.check_call(['git', 'pull', 'origin', BRANCH_NAME])\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "DRIVE_ROOT = Path('/content/drive/MyDrive/video-summary')\n",
    "INPUT_VIDEO_DRIVE = DRIVE_ROOT / 'input' / 'raw_video.mp4'\n",
    "PROCESSED_DRIVE = DRIVE_ROOT / 'processed'\n",
    "\n",
    "LOCAL_ROOT = Path('/content/video-summary-work')\n",
    "LOCAL_INPUT_DIR = LOCAL_ROOT / 'input'\n",
    "LOCAL_PROCESSED = LOCAL_ROOT / 'processed'\n",
    "LOCAL_INPUT_VIDEO = LOCAL_INPUT_DIR / INPUT_VIDEO_DRIVE.name\n",
    "\n",
    "for path in [DRIVE_ROOT, PROCESSED_DRIVE, LOCAL_INPUT_DIR, LOCAL_PROCESSED]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not INPUT_VIDEO_DRIVE.exists():\n",
    "    raise FileNotFoundError(f'Missing input video: {INPUT_VIDEO_DRIVE}')\n",
    "\n",
    "if (not LOCAL_INPUT_VIDEO.exists()) or (LOCAL_INPUT_VIDEO.stat().st_size != INPUT_VIDEO_DRIVE.stat().st_size):\n",
    "    shutil.copy2(INPUT_VIDEO_DRIVE, LOCAL_INPUT_VIDEO)\n",
    "\n",
    "VIDEO_PATH = str(LOCAL_INPUT_VIDEO)\n",
    "OUTPUT_ROOT = str(LOCAL_PROCESSED)\n",
    "VIDEO_NAME = Path(VIDEO_PATH).stem\n",
    "print('VIDEO_NAME =', VIDEO_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import importlib.util\n",
    "\n",
    "REPLAY_MODE = False\n",
    "SUMMARIZE_MAX_NEW_TOKENS = 512\n",
    "SUMMARIZE_BACKEND = os.environ.get('VIDEO_SUMMARY_SUMMARIZE_BACKEND', 'local').strip().lower()\n",
    "SUMMARIZE_FALLBACK_BACKEND = os.environ.get('VIDEO_SUMMARY_SUMMARIZE_FALLBACK_BACKEND', 'api').strip().lower()\n",
    "SUMMARIZE_LAST_RESORT_BACKEND = os.environ.get('VIDEO_SUMMARY_SUMMARIZE_LAST_RESORT_BACKEND', 'api').strip().lower()\n",
    "LOCAL_MODEL_VERSION = os.environ.get('VIDEO_SUMMARY_LOCAL_MODEL_VERSION', 'Qwen/Qwen2.5-3B-Instruct').strip()\n",
    "QC_ENFORCE_THRESHOLDS = os.environ.get('VIDEO_SUMMARY_QC_ENFORCE_THRESHOLDS', '1').strip() == '1'\n",
    "_valid_backends = {'api', 'local'}\n",
    "if (\n",
    "    SUMMARIZE_BACKEND not in _valid_backends\n",
    "    or SUMMARIZE_FALLBACK_BACKEND not in _valid_backends\n",
    "    or SUMMARIZE_LAST_RESORT_BACKEND not in _valid_backends\n",
    "):\n",
    "    raise ValueError('Invalid summarize backend. Supported: api, local')\n",
    "if not LOCAL_MODEL_VERSION:\n",
    "    raise ValueError('VIDEO_SUMMARY_LOCAL_MODEL_VERSION must not be empty')\n",
    "\n",
    "def _preflight_backend_support() -> dict:\n",
    "    has_transformers = importlib.util.find_spec('transformers') is not None\n",
    "    has_api_base = bool(os.environ.get('OPENAI_BASE_URL', '').strip())\n",
    "    has_api_key = bool(os.environ.get('OPENAI_API_KEY', '').strip())\n",
    "    api_ready = has_api_base and has_api_key\n",
    "    local_ready = has_transformers\n",
    "    if not os.environ.get('OPENAI_MODEL', '').strip():\n",
    "        os.environ['OPENAI_MODEL'] = LOCAL_MODEL_VERSION\n",
    "    return {\n",
    "        'local_ready': local_ready,\n",
    "        'api_ready': api_ready,\n",
    "        'has_api_base': has_api_base,\n",
    "        'has_api_key': has_api_key,\n",
    "    }\n",
    "\n",
    "BACKEND_PREFLIGHT = _preflight_backend_support()\n",
    "\n",
    "ARTIFACTS_LOCAL = LOCAL_PROCESSED / 'artifacts'\n",
    "ARTIFACTS_DRIVE = DRIVE_ROOT / 'artifacts'\n",
    "DELIVERABLES_LOCAL = LOCAL_PROCESSED / 'deliverables'\n",
    "DELIVERABLES_DRIVE = DRIVE_ROOT / 'deliverables'\n",
    "for path in [ARTIFACTS_LOCAL, ARTIFACTS_DRIVE, DELIVERABLES_LOCAL, DELIVERABLES_DRIVE]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUN_ID = datetime.now().strftime('colab_rnlp_%Y%m%d_%H%M%S')\n",
    "\n",
    "CLEAN_OLD_RUNS = True\n",
    "KEEP_LAST_RUNS = 3\n",
    "\n",
    "AUDIO_TRANSCRIPTS = PROCESSED_DRIVE / VIDEO_NAME / 'extraction' / 'audio_transcripts.json'\n",
    "VISUAL_CAPTIONS = PROCESSED_DRIVE / VIDEO_NAME / 'extraction' / 'visual_captions.json'\n",
    "RAW_VIDEO = INPUT_VIDEO_DRIVE\n",
    "\n",
    "if not AUDIO_TRANSCRIPTS.exists() or not VISUAL_CAPTIONS.exists():\n",
    "    raise FileNotFoundError('Missing perception outputs on Drive. Please run module1 + module2 first.')\n",
    "\n",
    "print('REPLAY_MODE =', REPLAY_MODE)\n",
    "print('RUN_ID =', RUN_ID)\n",
    "print('SUMMARIZE_BACKEND =', SUMMARIZE_BACKEND)\n",
    "print('SUMMARIZE_FALLBACK_BACKEND =', SUMMARIZE_FALLBACK_BACKEND)\n",
    "print('SUMMARIZE_LAST_RESORT_BACKEND =', SUMMARIZE_LAST_RESORT_BACKEND)\n",
    "print('LOCAL_MODEL_VERSION =', LOCAL_MODEL_VERSION)\n",
    "print('BACKEND_PREFLIGHT =', BACKEND_PREFLIGHT)\n",
    "print('QC_ENFORCE_THRESHOLDS =', QC_ENFORCE_THRESHOLDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def _build_backend_chain(primary: str, fallback: str, last_resort: str) -> list[str]:\n",
    "    chain = []\n",
    "    for item in [primary, fallback, last_resort]:\n",
    "        if item and item not in chain:\n",
    "            chain.append(item)\n",
    "    return chain\n",
    "\n",
    "def _select_chain_by_preflight(chain: list[str], preflight: dict) -> list[str]:\n",
    "    ready = []\n",
    "    for b in chain:\n",
    "        if b == 'local':\n",
    "            if preflight.get('local_ready', False):\n",
    "                ready.append(b)\n",
    "        elif b == 'api':\n",
    "            if preflight.get('api_ready', False):\n",
    "                ready.append(b)\n",
    "        else:\n",
    "            ready.append(b)\n",
    "    return ready or ['heuristic']\n",
    "\n",
    "def _run_pipeline_with_backend_chain(base_cmd: list[str], backend_chain: list[str]) -> None:\n",
    "    collected = []\n",
    "    max_tail_lines = 400\n",
    "    for idx, backend in enumerate(backend_chain):\n",
    "        next_backend = backend_chain[idx + 1] if idx + 1 < len(backend_chain) else backend_chain[-1]\n",
    "        cmd_try = list(base_cmd) + ['--summarize-backend', backend, '--summarize-fallback-backend', next_backend]\n",
    "        print(f'Attempt {idx+1}/{len(backend_chain)} with backend={backend}, fallback={next_backend}')\n",
    "\n",
    "        proc = subprocess.Popen(\n",
    "            cmd_try,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "        )\n",
    "\n",
    "        tail_lines = []\n",
    "        if proc.stdout is not None:\n",
    "            for line in proc.stdout:\n",
    "                print(line, end='')\n",
    "                tail_lines.append(line)\n",
    "                if len(tail_lines) > max_tail_lines:\n",
    "                    tail_lines = tail_lines[-max_tail_lines:]\n",
    "\n",
    "        return_code = proc.wait()\n",
    "        tail_text = ''.join(tail_lines)\n",
    "\n",
    "        if return_code == 0:\n",
    "            print(f'Pipeline success with backend={backend}')\n",
    "            return\n",
    "\n",
    "        collected.append((backend, return_code, tail_text))\n",
    "        print(f'Pipeline failed with backend={backend}, returncode={return_code}')\n",
    "        if tail_text:\n",
    "            print('--- combined output tail ---')\n",
    "            print(tail_text[-5000:])\n",
    "\n",
    "    lines = ['All backend attempts failed:']\n",
    "    for backend, code, tail_text in collected:\n",
    "        last_line = tail_text.strip().splitlines()[-1] if tail_text.strip() else f'returncode={code}'\n",
    "        lines.append(f'- {backend}: {last_line}')\n",
    "    raise RuntimeError('\\n'.join(lines))\n",
    "\n",
    "artifacts_root = ARTIFACTS_DRIVE if REPLAY_MODE else ARTIFACTS_LOCAL\n",
    "deliverables_root = DELIVERABLES_DRIVE if REPLAY_MODE else DELIVERABLES_LOCAL\n",
    "print('artifacts_root =', artifacts_root)\n",
    "print('deliverables_root =', deliverables_root)\n",
    "backend_plan = _build_backend_chain(SUMMARIZE_BACKEND, SUMMARIZE_FALLBACK_BACKEND, SUMMARIZE_LAST_RESORT_BACKEND)\n",
    "selected_chain = _select_chain_by_preflight(backend_plan, BACKEND_PREFLIGHT)\n",
    "print('Backend priority plan =', backend_plan)\n",
    "print('Backend chain after preflight =', selected_chain)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    '-m',\n",
    "    'reasoning_nlp.pipeline_runner',\n",
    "    '--audio-transcripts', str(AUDIO_TRANSCRIPTS),\n",
    "    '--visual-captions', str(VISUAL_CAPTIONS),\n",
    "    '--raw-video', str(RAW_VIDEO),\n",
    "    '--stage', 'g8',\n",
    "    '--run-id', RUN_ID,\n",
    "    '--artifacts-root', str(artifacts_root),\n",
    "    '--deliverables-root', str(deliverables_root),\n",
    "    '--summarize-max-new-tokens', str(SUMMARIZE_MAX_NEW_TOKENS),\n",
    "]\n",
    "if QC_ENFORCE_THRESHOLDS:\n",
    "    cmd.append('--qc-enforce-thresholds')\n",
    "if REPLAY_MODE:\n",
    "    cmd.append('--replay')\n",
    "\n",
    "_run_pipeline_with_backend_chain(cmd, selected_chain)\n",
    "print('Pipeline completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "source_run_dir = (ARTIFACTS_DRIVE if REPLAY_MODE else ARTIFACTS_LOCAL) / RUN_ID\n",
    "drive_run_dir = ARTIFACTS_DRIVE / RUN_ID\n",
    "source_deliverable_dir = (DELIVERABLES_DRIVE if REPLAY_MODE else DELIVERABLES_LOCAL) / RUN_ID\n",
    "drive_deliverable_dir = DELIVERABLES_DRIVE / RUN_ID\n",
    "\n",
    "def _copy_item(src: Path, dst: Path) -> None:\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if src.is_dir():\n",
    "        if dst.exists():\n",
    "            shutil.rmtree(dst)\n",
    "        shutil.copytree(src, dst)\n",
    "    else:\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "keep_rel_paths = [\n",
    "    'run_meta.json',\n",
    "    'g1_validate/normalized_input.json',\n",
    "    'g2_align/alignment_result.json',\n",
    "    'g3_context/context_blocks.json',\n",
    "    'g4_summarize/parse_meta.json',\n",
    "    'g4_summarize/summary_script.internal.json',\n",
    "    'g5_segment/summary_script.json',\n",
    "    'g5_segment/summary_video_manifest.json',\n",
    "    'g6_manifest/manifest_validation.json',\n",
    "    'g7_assemble/render_meta.json',\n",
    "    'g7_assemble/summary_video.mp4',\n",
    "    'g8_qc/quality_report.json',\n",
    "]\n",
    "for rel in keep_rel_paths:\n",
    "    _copy_item(source_run_dir / rel, drive_run_dir / rel)\n",
    "for rel in ['summary_video.mp4', 'summary_text.txt']:\n",
    "    _copy_item(source_deliverable_dir / rel, drive_deliverable_dir / rel)\n",
    "\n",
    "if CLEAN_OLD_RUNS and KEEP_LAST_RUNS > 0:\n",
    "    all_runs = [p for p in ARTIFACTS_DRIVE.iterdir() if p.is_dir() and p.name.startswith('colab_rnlp_')]\n",
    "    all_runs.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    for old in all_runs[KEEP_LAST_RUNS:]:\n",
    "        if old.name != RUN_ID:\n",
    "            shutil.rmtree(old, ignore_errors=True)\n",
    "\n",
    "print('Synced balanced artifacts to Drive:', drive_run_dir)\n",
    "print('Synced final deliverables to Drive:', drive_deliverable_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "RUN_DIR = ARTIFACTS_DRIVE / RUN_ID\n",
    "FINAL_DIR = DELIVERABLES_DRIVE / RUN_ID\n",
    "OUTPUT_TEXT = FINAL_DIR / 'summary_text.txt'\n",
    "INTERNAL_SUMMARY = RUN_DIR / 'g4_summarize' / 'summary_script.internal.json'\n",
    "ALIGNMENT = RUN_DIR / 'g2_align' / 'alignment_result.json'\n",
    "REPORT = RUN_DIR / 'g8_qc' / 'quality_report.json'\n",
    "\n",
    "def _safe_json(path):\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(path.read_text(encoding='utf-8'))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _split_sentences(text):\n",
    "    chunks = [x.strip() for x in re.split(r'[\\n\\r]+|(?<=[.!?])\\s+', text) if x.strip()]\n",
    "    return chunks\n",
    "\n",
    "def _asciiish_ratio(text):\n",
    "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text)\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    asciiish = sum(1 for w in words if all(ord(c) < 128 for c in w))\n",
    "    return asciiish / len(words)\n",
    "\n",
    "def _garble_ratio(lines):\n",
    "    if not lines:\n",
    "        return 0.0\n",
    "    bad = 0\n",
    "    for line in lines:\n",
    "        words = re.findall(r'\\w+', line, flags=re.UNICODE)\n",
    "        if len(words) < 4:\n",
    "            continue\n",
    "        short_ratio = sum(1 for w in words if len(w) <= 2) / max(1, len(words))\n",
    "        digit_ratio = sum(ch.isdigit() for ch in line) / max(1, len(line))\n",
    "        if short_ratio > 0.45 or digit_ratio > 0.35:\n",
    "            bad += 1\n",
    "    return bad / len(lines)\n",
    "\n",
    "def _template_hits(text):\n",
    "    templates = [\n",
    "        'Noi dung cho thay dien bien theo thu tu thoi gian',\n",
    "        'Thong diep duoc rut ra tu cac su kien da xuat hien trong video',\n",
    "        'Khong du du lieu de tao tom tat chi tiet',\n",
    "        'Khong du du lieu de tom tat chi tiet',\n",
    "    ]\n",
    "    lowered = text.lower()\n",
    "    return [t for t in templates if t.lower() in lowered]\n",
    "\n",
    "summary_text = OUTPUT_TEXT.read_text(encoding='utf-8') if OUTPUT_TEXT.exists() else ''\n",
    "internal = _safe_json(INTERNAL_SUMMARY) or {}\n",
    "alignment = _safe_json(ALIGNMENT) or {}\n",
    "quality = _safe_json(REPORT) or {}\n",
    "\n",
    "lines = _split_sentences(summary_text)\n",
    "backend = str((internal.get('generation_meta') or {}).get('backend', 'unknown'))\n",
    "plot = str(internal.get('plot_summary', ''))\n",
    "moral = str(internal.get('moral_lesson', ''))\n",
    "template_matches = _template_hits('\\n'.join([plot, moral, summary_text]))\n",
    "ascii_ratio = _asciiish_ratio(summary_text)\n",
    "garble_ratio = _garble_ratio(lines)\n",
    "\n",
    "blocks = alignment.get('blocks', []) if isinstance(alignment, dict) else []\n",
    "fallback_counter = Counter(str(x.get('fallback_type', '')) for x in blocks if isinstance(x, dict))\n",
    "no_match_rate = 0.0\n",
    "if blocks:\n",
    "    no_match_rate = fallback_counter.get('no_match', 0) / len(blocks)\n",
    "\n",
    "score = 100\n",
    "if backend == 'heuristic':\n",
    "    score -= 35\n",
    "score -= min(25, int(100 * no_match_rate * 0.4))\n",
    "score -= min(20, int(100 * garble_ratio * 0.4))\n",
    "score -= min(20, int(100 * max(0.0, ascii_ratio - 0.55) * 0.5))\n",
    "score -= 10 * len(template_matches)\n",
    "score = max(0, score)\n",
    "\n",
    "severity = 'good' if score >= 80 else ('warning' if score >= 60 else 'poor')\n",
    "\n",
    "print('--- Auto diagnose summary quality ---')\n",
    "print('Run ID:', RUN_ID)\n",
    "print('Backend:', backend)\n",
    "print('Score:', score, f'({severity})')\n",
    "print('No-match rate:', f'{no_match_rate:.3f}')\n",
    "print('Garble ratio:', f'{garble_ratio:.3f}')\n",
    "print('ASCII-ish ratio:', f'{ascii_ratio:.3f}')\n",
    "print('Template hits:', template_matches if template_matches else 'none')\n",
    "if isinstance(quality, dict):\n",
    "    print('QC overall_status:', quality.get('overall_status', 'unknown'))\n",
    "\n",
    "issues = []\n",
    "if backend == 'heuristic':\n",
    "    issues.append('Dang dung heuristic summary; noi dung de bi template hoa.')\n",
    "if no_match_rate > 0.30:\n",
    "    issues.append('Alignment no_match_rate cao, de gay ghiep sai thoai-canh.')\n",
    "if garble_ratio > 0.25:\n",
    "    issues.append('Nhieu cau co dau hieu nhieu ASR noise/vo nghia.')\n",
    "if ascii_ratio > 0.65:\n",
    "    issues.append('Ty le tu ASCII cao, co kha nang tron caption/thoai tieng Anh.')\n",
    "if template_matches:\n",
    "    issues.append('Phat hien cau mau co dinh trong tom tat.')\n",
    "\n",
    "print('Detected issues:')\n",
    "if issues:\n",
    "    for idx, item in enumerate(issues, start=1):\n",
    "        print(f'{idx}. {item}')\n",
    "else:\n",
    "    print('1. Khong phat hien dau hieu bat thuong ro rang theo rule hien tai.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Video\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "RUN_DIR = ARTIFACTS_DRIVE / RUN_ID\n",
    "FINAL_DIR = DELIVERABLES_DRIVE / RUN_ID\n",
    "ALIGNMENT = RUN_DIR / 'g2_align' / 'alignment_result.json'\n",
    "SCRIPT = RUN_DIR / 'g5_segment' / 'summary_script.json'\n",
    "MANIFEST = RUN_DIR / 'g5_segment' / 'summary_video_manifest.json'\n",
    "REPORT = RUN_DIR / 'g8_qc' / 'quality_report.json'\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable,\n",
    "    'docs/Reasoning-NLP/schema/validate_artifacts.py',\n",
    "    '--alignment', str(ALIGNMENT),\n",
    "    '--script', str(SCRIPT),\n",
    "    '--manifest', str(MANIFEST),\n",
    "    '--report', str(REPORT),\n",
    "    '--contracts-dir', 'contracts/v1/template',\n",
    "])\n",
    "\n",
    "OUTPUT_VIDEO = FINAL_DIR / 'summary_video.mp4'\n",
    "OUTPUT_TEXT = FINAL_DIR / 'summary_text.txt'\n",
    "print('Output video:', OUTPUT_VIDEO)\n",
    "print('Output text:', OUTPUT_TEXT)\n",
    "print('--- Summary text preview ---')\n",
    "print(OUTPUT_TEXT.read_text(encoding='utf-8'))\n",
    "Video(str(OUTPUT_VIDEO), embed=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "module3_reasoning_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
