{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline (Module 1 -> 2 -> 3) on Colab\n",
    "\n",
    "This notebook runs the complete system:\n",
    "1. Module 1 Extraction\n",
    "2. Module 2 Perception (ASR + captions)\n",
    "3. Module 3 Reasoning NLP (G1->G8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def _ensure_ffmpeg():\n",
    "    if Path('/usr/bin/ffmpeg').exists():\n",
    "        print('ffmpeg already installed')\n",
    "        return\n",
    "    subprocess.check_call(['apt-get', 'update', '-y'])\n",
    "    subprocess.check_call(['apt-get', 'install', '-y', 'ffmpeg'])\n",
    "\n",
    "def _ensure_packages():\n",
    "    req = {\n",
    "        'scenedetect': 'scenedetect',\n",
    "        'cv2': 'opencv-python-headless',\n",
    "        'faster_whisper': 'faster-whisper',\n",
    "        'transformers': 'transformers',\n",
    "        'PIL': 'pillow',\n",
    "        'tqdm': 'tqdm',\n",
    "        'jsonschema': 'jsonschema',\n",
    "    }\n",
    "    miss = [pip for mod,pip in req.items() if importlib.util.find_spec(mod) is None]\n",
    "    if not miss:\n",
    "        print('python packages already satisfied')\n",
    "        return\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', *miss])\n",
    "\n",
    "_ensure_ffmpeg()\n",
    "_ensure_packages()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path('/content/video-summary')\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.check_call(['git', 'clone', 'https://github.com/TCTri205/video-summary.git', str(REPO_DIR)])\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n",
    "print('GPU:', gpu_name)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    RUNTIME_PROFILE = 'CPU'\n",
    "elif 'L4' in gpu_name.upper():\n",
    "    RUNTIME_PROFILE = 'L4'\n",
    "else:\n",
    "    RUNTIME_PROFILE = 'T4'\n",
    "\n",
    "CAPTION_BATCH_BY_PROFILE = {\n",
    "    'CPU': 1,\n",
    "    'T4': 4,\n",
    "    'L4': 8,\n",
    "}\n",
    "SUMMARIZE_TOKENS_BY_PROFILE = {\n",
    "    'CPU': 256,\n",
    "    'T4': 384,\n",
    "    'L4': 512,\n",
    "}\n",
    "CAPTION_BATCH_SIZE = CAPTION_BATCH_BY_PROFILE[RUNTIME_PROFILE]\n",
    "SUMMARIZE_MAX_NEW_TOKENS = SUMMARIZE_TOKENS_BY_PROFILE[RUNTIME_PROFILE]\n",
    "\n",
    "DRIVE_ROOT = Path('/content/drive/MyDrive/video-summary')\n",
    "INPUT_VIDEO_DRIVE = DRIVE_ROOT / 'input' / 'raw_video.mp4'\n",
    "PROCESSED_DRIVE = DRIVE_ROOT / 'processed'\n",
    "ARTIFACTS_DRIVE = DRIVE_ROOT / 'artifacts'\n",
    "\n",
    "LOCAL_ROOT = Path('/content/video-summary-work')\n",
    "LOCAL_INPUT_DIR = LOCAL_ROOT / 'input'\n",
    "LOCAL_PROCESSED = LOCAL_ROOT / 'processed'\n",
    "LOCAL_ARTIFACTS = LOCAL_ROOT / 'artifacts'\n",
    "\n",
    "for path in [PROCESSED_DRIVE, ARTIFACTS_DRIVE, LOCAL_INPUT_DIR, LOCAL_PROCESSED, LOCAL_ARTIFACTS]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not INPUT_VIDEO_DRIVE.exists():\n",
    "    raise FileNotFoundError(f'Missing input video: {INPUT_VIDEO_DRIVE}')\n",
    "\n",
    "LOCAL_VIDEO = LOCAL_INPUT_DIR / INPUT_VIDEO_DRIVE.name\n",
    "if (not LOCAL_VIDEO.exists()) or (LOCAL_VIDEO.stat().st_size != INPUT_VIDEO_DRIVE.stat().st_size):\n",
    "    shutil.copy2(INPUT_VIDEO_DRIVE, LOCAL_VIDEO)\n",
    "\n",
    "RAW_VIDEO_LOCAL = str(LOCAL_VIDEO)\n",
    "RAW_VIDEO_DRIVE = str(INPUT_VIDEO_DRIVE)\n",
    "VIDEO_NAME = LOCAL_VIDEO.stem\n",
    "\n",
    "RUN_ID = os.environ.get('VIDEO_SUMMARY_RUN_ID', '').strip() or f'colab_full_{VIDEO_NAME}_{int(time.time())}'\n",
    "REPLAY_MODE = False\n",
    "KEEP_LAST_RUNS = 2\n",
    "CLEAN_OLD_RUNS = True\n",
    "CLEAN_HEAVY_EXTRACTION = True\n",
    "\n",
    "print('RUNTIME_PROFILE =', RUNTIME_PROFILE)\n",
    "print('CAPTION_BATCH_SIZE =', CAPTION_BATCH_SIZE)\n",
    "print('SUMMARIZE_MAX_NEW_TOKENS =', SUMMARIZE_MAX_NEW_TOKENS)\n",
    "print('VIDEO_NAME =', VIDEO_NAME)\n",
    "print('RUN_ID =', RUN_ID)\n",
    "print('REPLAY_MODE =', REPLAY_MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29902df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extraction_perception.extraction.extraction import VideoPreprocessor\n",
    "\n",
    "if REPLAY_MODE:\n",
    "    print('Replay mode enabled: skip Module 1 extraction')\n",
    "else:\n",
    "    processor = VideoPreprocessor(video_path=RAW_VIDEO_LOCAL, output_root=str(LOCAL_PROCESSED))\n",
    "    timestamps = processor.detect_scenes()\n",
    "    audio_path = processor.extract_audio()\n",
    "    metadata = processor.extract_keyframes_and_metadata(timestamps)\n",
    "    print('Scenes:', len(timestamps))\n",
    "    print('Audio:', audio_path)\n",
    "    print('Keyframes:', metadata.get('total_keyframes', 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb555e",
   "metadata": {},
   "source": [
    "## Step 1 - Module 1 Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f469f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from extraction_perception.extraction.whisper_module import WhisperExtractor\n",
    "from extraction_perception.perception.caption import VisualCaptioner\n",
    "\n",
    "LOCAL_EXTRACTION_DIR = LOCAL_PROCESSED / VIDEO_NAME / 'extraction'\n",
    "AUDIO_PATH = LOCAL_EXTRACTION_DIR / 'audio' / 'audio_16k.wav'\n",
    "METADATA_PATH = LOCAL_EXTRACTION_DIR / 'scene_metadata.json'\n",
    "CAPTIONS_PATH = LOCAL_EXTRACTION_DIR / 'visual_captions.json'\n",
    "\n",
    "if REPLAY_MODE:\n",
    "    print('Replay mode enabled: skip Module 2 perception')\n",
    "else:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    compute_type = 'float16' if device == 'cuda' else 'int8'\n",
    "\n",
    "    asr = WhisperExtractor(model_size='base', device=device, compute_type=compute_type)\n",
    "    asr.transcribe(\n",
    "        input_path=str(AUDIO_PATH),\n",
    "        language='vi',\n",
    "        output_root=str(LOCAL_PROCESSED),\n",
    "        output_name=VIDEO_NAME,\n",
    "    )\n",
    "\n",
    "    captioner = VisualCaptioner()\n",
    "    captioner.caption_from_metadata(\n",
    "        metadata_path=str(METADATA_PATH),\n",
    "        output_path=str(CAPTIONS_PATH),\n",
    "        batch_size=CAPTION_BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    del asr\n",
    "    del captioner\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35077b30",
   "metadata": {},
   "source": [
    "## Step 2 - Module 2 Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "DRIVE_EXTRACTION_DIR = PROCESSED_DRIVE / VIDEO_NAME / 'extraction'\n",
    "DRIVE_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not REPLAY_MODE:\n",
    "    sync_to_drive = [\n",
    "        ('scene_metadata.json', 'scene_metadata.json'),\n",
    "        ('audio_transcripts.json', 'audio_transcripts.json'),\n",
    "        ('visual_captions.json', 'visual_captions.json'),\n",
    "    ]\n",
    "    for src_rel, dst_rel in sync_to_drive:\n",
    "        src = LOCAL_EXTRACTION_DIR / src_rel\n",
    "        dst = DRIVE_EXTRACTION_DIR / dst_rel\n",
    "        if src.exists():\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "AUDIO_TRANSCRIPTS = DRIVE_EXTRACTION_DIR / 'audio_transcripts.json'\n",
    "VISUAL_CAPTIONS = DRIVE_EXTRACTION_DIR / 'visual_captions.json'\n",
    "\n",
    "if not AUDIO_TRANSCRIPTS.exists() or not VISUAL_CAPTIONS.exists():\n",
    "    raise FileNotFoundError('Missing perception outputs on Drive for reasoning stage')\n",
    "\n",
    "print('Drive transcripts/captions ready')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e095ca",
   "metadata": {},
   "source": [
    "## Step 3 - Module 3 Reasoning (G1->G8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114866dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "artifacts_root = ARTIFACTS_DRIVE if REPLAY_MODE else LOCAL_ARTIFACTS\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    '-m',\n",
    "    'reasoning_nlp.pipeline_runner',\n",
    "    '--audio-transcripts', str(AUDIO_TRANSCRIPTS),\n",
    "    '--visual-captions', str(VISUAL_CAPTIONS),\n",
    "    '--raw-video', RAW_VIDEO_DRIVE,\n",
    "    '--stage', 'g8',\n",
    "    '--run-id', RUN_ID,\n",
    "    '--artifacts-root', str(artifacts_root),\n",
    "    '--summarize-backend', 'local',\n",
    "    '--summarize-fallback-backend', 'local',\n",
    "    '--summarize-max-new-tokens', str(SUMMARIZE_MAX_NEW_TOKENS),\n",
    "]\n",
    "if REPLAY_MODE:\n",
    "    cmd.append('--replay')\n",
    "\n",
    "subprocess.check_call(cmd)\n",
    "print('Reasoning pipeline completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "source_run_dir = (ARTIFACTS_DRIVE if REPLAY_MODE else LOCAL_ARTIFACTS) / RUN_ID\n",
    "drive_run_dir = ARTIFACTS_DRIVE / RUN_ID\n",
    "\n",
    "def _copy_item(src: Path, dst: Path) -> None:\n",
    "    if not src.exists():\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if src.is_dir():\n",
    "        if dst.exists():\n",
    "            shutil.rmtree(dst)\n",
    "        shutil.copytree(src, dst)\n",
    "    else:\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "keep_rel_paths = [\n",
    "    'run_meta.json',\n",
    "    'g1_validate/normalized_input.json',\n",
    "    'g2_align/alignment_result.json',\n",
    "    'g3_context/context_blocks.json',\n",
    "    'g4_summarize/parse_meta.json',\n",
    "    'g4_summarize/summary_script.internal.json',\n",
    "    'g5_segment/summary_script.json',\n",
    "    'g5_segment/summary_video_manifest.json',\n",
    "    'g6_manifest/manifest_validation.json',\n",
    "    'g7_assemble/render_meta.json',\n",
    "    'g7_assemble/summary_video.mp4',\n",
    "    'g8_qc/quality_report.json',\n",
    "]\n",
    "for rel in keep_rel_paths:\n",
    "    _copy_item(source_run_dir / rel, drive_run_dir / rel)\n",
    "\n",
    "if CLEAN_HEAVY_EXTRACTION and DRIVE_EXTRACTION_DIR.exists():\n",
    "    heavy_items = [\n",
    "        DRIVE_EXTRACTION_DIR / 'keyframes',\n",
    "        DRIVE_EXTRACTION_DIR / 'audio' / 'audio_16k.wav',\n",
    "    ]\n",
    "    for item in heavy_items:\n",
    "        if item.is_dir():\n",
    "            shutil.rmtree(item, ignore_errors=True)\n",
    "        elif item.exists():\n",
    "            item.unlink()\n",
    "\n",
    "if CLEAN_OLD_RUNS and KEEP_LAST_RUNS > 0:\n",
    "    all_runs = [p for p in ARTIFACTS_DRIVE.iterdir() if p.is_dir() and p.name.startswith('colab_full_')]\n",
    "    all_runs.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    for old in all_runs[KEEP_LAST_RUNS:]:\n",
    "        if old.name != RUN_ID:\n",
    "            shutil.rmtree(old, ignore_errors=True)\n",
    "\n",
    "print('Synced balanced artifacts to Drive:', drive_run_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "RUN_DIR = ARTIFACTS_DRIVE / RUN_ID\n",
    "ALIGNMENT = RUN_DIR / 'g2_align' / 'alignment_result.json'\n",
    "SCRIPT = RUN_DIR / 'g5_segment' / 'summary_script.json'\n",
    "MANIFEST = RUN_DIR / 'g5_segment' / 'summary_video_manifest.json'\n",
    "REPORT = RUN_DIR / 'g8_qc' / 'quality_report.json'\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable,\n",
    "    'docs/Reasoning-NLP/schema/validate_artifacts.py',\n",
    "    '--alignment', str(ALIGNMENT),\n",
    "    '--script', str(SCRIPT),\n",
    "    '--manifest', str(MANIFEST),\n",
    "    '--report', str(REPORT),\n",
    "    '--contracts-dir', 'contracts/v1/template',\n",
    "])\n",
    "\n",
    "OUTPUT_VIDEO = RUN_DIR / 'g7_assemble' / 'summary_video.mp4'\n",
    "print('Output video:', OUTPUT_VIDEO)\n",
    "Video(str(OUTPUT_VIDEO), embed=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "full_pipeline_m1_m2_m3_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
